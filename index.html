<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG" />
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG" />
  <meta property="og:url" content="URL OF THE WEBSITE" />
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200" />
  <meta property="og:image:height" content="630" />


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>QN-Mixer: A Quasi-Newton MLP-Mixer Model for Sparse-View CT Reconstruction</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>

<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">QN-Mixer: A Quasi-Newton MLP-Mixer Model for Sparse-View CT
              Reconstruction</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">Ishak Ayad</a><sup>*</sup>,</span>
              <span class="author-block">
                <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Nicolas Larue</a><sup>*</sup>,</span>
              <span class="author-block">
                <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Maï K. Nguyen</a>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">Institution Name<br>CVPR 2024</span>
              <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- Arxiv PDF link -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>

                <!-- Supplementary PDF link -->
                <span class="link-block">
                  <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Supplementary</span>
                  </a>
                </span>

                <!-- Github link -->
                <span class="link-block">
                  <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>


  <!-- Teaser Image-->
  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <img src="static/images/teaser.png" alt="Teaser Image" />
        <h2 class="subtitle has-text-centered">
          The paper introduces a novel neural network called QN-Mixer, which employs a latent BFGS algorithm
          to approximate the Hessian matrix with a deep-net learned regularization term.
          It outperforms state-of-the-art methods in terms of quantitative metrics while requiring fewer
          iterations than first-order unrolling networks.
        </h2>
      </div>
    </div>
  </section>
  <!-- End teaser video -->

  <!-- Paper abstract -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Inverse problems span across diverse fields. In medical contexts, computed tomography (CT) plays a crucial
              role in reconstructing a patient's internal structure, presenting challenges due to artifacts caused by
              inherently ill-posed inverse problems. Previous research advanced image quality via post-processing and
              deep unrolling algorithms but faces challenges, such as extended convergence times with ultra-sparse data.
              Despite enhancements, resulting images often show significant artifacts, limiting their effectiveness for
              real-world diagnostic applications. We aim to explore deep second-order unrolling algorithms for solving
              imaging inverse problems, emphasizing their faster convergence and lower time complexity compared to
              common first-order methods like gradient descent. In this paper, we introduce QN-Mixer, an algorithm based
              on the quasi-Newton approach. We use learned parameters through the BFGS algorithm and introduce
              Incept-Mixer, an efficient neural architecture that serves as a non-local regularization term, capturing
              long-range dependencies within images. To address the computational demands typically associated with
              quasi-Newton algorithms that require full Hessian matrix computations, we present a memory-efficient
              alternative. Our approach intelligently downsamples gradient information, significantly reducing
              computational requirements while maintaining performance. The approach is validated through experiments on
              the sparse-view CT problem, involving various datasets and scanning protocols, and is compared with
              post-processing and deep unrolling state-of-the-art approaches. Our method outperforms existing approaches
              and achieves state-of-the-art performance in terms of SSIM and PSNR, all while reducing the number of
              unrolling iterations required.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End paper abstract -->

  <!-- Problem -->
  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <h2 class="title is-3">Sparse-View Reconstruction Challenges</h2>
        <img src="static/images/sparse_view_ct.png" alt="problem" />
        <p class="content has-text-justified">
          Computed tomography (CT) is a widely used imaging modality in medical diagnosis and treatment planning,
          delivering intricate anatomical details of the human body with precision. Despite its success, CT is
          associated with high radiation doses, which can increase the risk of cancer induction.
          Adhering to the ALARA principle (As Low As Reasonably Achievable), the medical community emphasizes minimizing
          radiation exposure to the lowest level necessary for accurate diagnosis.
          Numerous approaches have been proposed to reduce radiation doses while maintaining image quality.
          Among these, sparse-view CT emerges as a promising solution, effectively lowering radiation doses by
          subsampling the projection data, often referred to as the sinogram.
          Nonetheless, reconstructed images using the well-known Filtered Back Projection (FBP) algorithm suffer from
          pronounced streaking artifacts, which can lead to misdiagnosis.
          The challenge of effectively reconstructing high-quality CT images from sparse-view data is
          gaining increasing attention in both the computer vision and medical imaging communities.
        </p>
      </div>
    </div>
    </div>
  </section>
  <!-- End method overview -->


  <!-- Method overview -->
  <section class="hero is-small is-light">
    <div class="hero-body">
      <div class="container">
        <h2 class="title is-3">Methodology</h2>

        <!-- Your image here -->
        <img src="static/images/overview.png" alt="overview" />

        <p class="content has-text-justified">
          The figure above illustrates the QN-Mixer architecture.
          Our method is a new type of second-order unrolling network, drawing inspiration from the quasi-Newton method.
          It approximates the inverse Hessian matrix using a latent BFGS algorithm and incorporates a non-local
          regularization term, Incept-Mixer, aimed at capturing non-local relationships. To address the computational
          challenges associated with full inverse Hessian matrix approximation, a latent BFGS algorithm is utilized.
        </p>

      </div>
    </div>
    </div>
  </section>
  <!-- End method overview -->

  <!-- Image carousel -->
  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item">
            <!-- Your image here -->
            <img src="static/images/visual_aapm.png" alt="AAPM" />
            <h2 class="subtitle has-text-centered">
              Visual comparison on AAPM.
            </h2>
          </div>
          <div class="item">
            <!-- Your image here -->
            <img src="static/images/visual_aapm_2.png" alt="AAPM" />
            <h2 class="subtitle has-text-centered">
              Visual comparison on AAPM.
            </h2>
          </div>
          <div class="item">
            <!-- Your image here -->
            <img src="static/images/visual_lesion.png" alt="Deeplesion/">
            <h2 class="subtitle has-text-centered">
              Visual comparison on Deeplesion.
            </h2>
          </div>
          <div class="item">
            <!-- Your image here -->
            <img src="static/images/visual_lesion_2.png" alt="Deeplesion/">
            <h2 class="subtitle has-text-centered">
              Visual comparison on Deeplesion.
            </h2>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End image carousel -->


  <!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
        @inproceedings{ayad2024,
          title={QN-Mixer: A Quasi-Newton MLP-Mixer Model for Sparse-View CT Reconstruction}, 
          author={Ayad, Ishak and Larue Nicolas and Nguyen, Maï K.},
          booktitle={CVPR},
          year={2024},
        } 
    </code></pre>
    </div>
  </section>
  <!--End BibTex citation -->


  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">

            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                target="_blank">Academic Project Page Template</a> which was adopted from the <a
                href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
              <br> This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>

          </div>
        </div>
      </div>
    </div>
  </footer>

  <!-- Statcounter tracking code -->

  <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

  <!-- End of Statcounter Code -->

</body>

</html>